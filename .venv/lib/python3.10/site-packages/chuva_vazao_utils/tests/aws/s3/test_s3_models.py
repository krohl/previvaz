import os
import pytest
from botocore.exceptions import ClientError
from pytest_mock import MockerFixture
from unittest.mock import MagicMock

from chuva_vazao_utils.aws.s3.s3_models import S3File, S3Folder

MODULE_PATH = 'chuva_vazao_utils.aws.s3.s3_models'


@pytest.fixture
def mock_os(mocker: MockerFixture) -> MagicMock:
    return mocker.patch(f'{MODULE_PATH}.os')


@pytest.fixture
def create_mock_file_s3(tmpdir, s3_resource_mock):
    def _create_mock_file_s3(filename: str, mock_bucket: str, mock_base_path: str):
        tmpdir.join(filename).write(filename)
        local_file_mock = os.path.join(tmpdir, filename)
        file_key = f'{mock_base_path}/{filename}'

        s3_resource_mock.Bucket(mock_bucket).upload_file(local_file_mock, file_key)

        return file_key
    return _create_mock_file_s3


#####################################################################
# S3Folder
#####################################################################
def test_exists(create_bucket_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)
    create_mock_file_s3('file1.txt', mock_bucket, base_key)

    folder = S3Folder(base_key, mock_bucket)
    # When/Then
    assert folder.exists()


def test_not_exists(create_bucket_mock):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)

    folder = S3Folder(base_key, mock_bucket)
    # When/Then
    assert not folder.exists()


def test_exists_boto_error(s3_client_mock):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    folder = S3Folder(base_key, mock_bucket)
    # When/Then
    with pytest.raises(ClientError):
        folder.exists()


def test_download(tmpdir, create_bucket_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)
    create_mock_file_s3('file1.txt', mock_bucket, base_key)
    create_mock_file_s3('file2.txt', mock_bucket, base_key)
    folder_dst = tmpdir.mkdir('dst')

    folder = S3Folder(base_key, mock_bucket)
    # When
    folder.download(str(folder_dst))
    # Then
    assert os.path.exists(os.path.join(tmpdir, folder_dst, 'file1.txt'))
    assert os.path.exists(os.path.join(tmpdir, folder_dst, 'file2.txt'))


def test_upload(mock_os: MagicMock):
    # Given
    folder = S3Folder('mock/base/path', 'mock_bucket')
    # When
    folder.upload('local/folder')
    # Then
    mock_os.system.assert_called_once_with(
        'aws s3 sync local/folder s3://mock_bucket/mock/base/path --acl bucket-owner-full-control'
    )


def test_delete(create_bucket_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)
    create_mock_file_s3('file1.txt', mock_bucket, base_key)

    folder = S3Folder(base_key, mock_bucket)
    # When
    assert folder.exists()
    folder.delete()
    # Then
    assert not folder.exists()


def test_list_keys(create_bucket_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)
    file1_key = create_mock_file_s3('file1.txt', mock_bucket, base_key)
    file2_key = create_mock_file_s3('file2.txt', mock_bucket, base_key)
    file3_key = create_mock_file_s3('file3.txt', mock_bucket, base_key)
    file4_key = create_mock_file_s3('file4.txt', mock_bucket, base_key)
    expected_keys = [file1_key, file2_key, file3_key, file4_key]

    folder = S3Folder(base_key, mock_bucket)
    # when
    s3_keys = folder.list_keys()
    # Then
    assert s3_keys == expected_keys


def test_get_oldest_newest_file_datetime(create_bucket_mock, s3_resource_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'

    create_bucket_mock(mock_bucket)
    file1_key = create_mock_file_s3('file1.txt', mock_bucket, base_key)
    create_mock_file_s3('file2.txt', mock_bucket, base_key)
    create_mock_file_s3('file3.txt', mock_bucket, base_key)
    file4_key = create_mock_file_s3('file4.txt', mock_bucket, base_key)

    file1_s3_object = [f for f in s3_resource_mock.Bucket(mock_bucket).objects.filter(Prefix=file1_key).all()][0]
    file4_s3_object = [f for f in s3_resource_mock.Bucket(mock_bucket).objects.filter(Prefix=file4_key).all()][0]

    folder = S3Folder(base_key, mock_bucket)
    # when
    oldest_file_datetime = folder.get_oldest_file_datetime()
    newest_file_datetime = folder.get_newest_file_datetime()
    # Then
    assert oldest_file_datetime == file1_s3_object.last_modified
    assert newest_file_datetime == file4_s3_object.last_modified


def test_get_oldest_newest_file_datetime_empty_folder(create_bucket_mock):
    # Given
    mock_bucket = 'mock_bucket'
    create_bucket_mock(mock_bucket)

    folder = S3Folder('mock/base/path', 'mock_bucket')
    # When
    oldest_datetime = folder.get_oldest_file_datetime()
    newest_file_datetime = folder.get_newest_file_datetime()
    # Then
    assert oldest_datetime == None
    assert newest_file_datetime == None


def test_copy_contents_from(mock_os: MagicMock):
    # Given
    folder1 = S3Folder('mock/base/path_1', 'mock_bucket')
    folder2 = S3Folder('mock/base/path_2', 'mock_bucket')
    # When
    folder1.copy_contents_from(folder2)
    # Then
    mock_os.system.assert_called_once_with(
        'aws s3 sync s3://mock_bucket/mock/base/path_2 s3://mock_bucket/mock/base/path_1 --acl bucket-owner-full-control'
    )


def test_copy_contents_from_identical_files(mock_os: MagicMock):
    # Given
    folder1 = S3Folder('mock/base/path', 'mock_bucket')
    folder2 = S3Folder('mock/base/path', 'mock_bucket')
    # When
    folder1.copy_contents_from(folder2)
    # Then
    mock_os.system.assert_not_called()


#####################################################################
# S3File
#####################################################################
def test_create_from_key_bucket():
    # Given
    key = 'test/s3/path/filename.dat'
    bucket = 'mock_bucket'
    # When
    s3_file = S3File.create_from_key_bucket(key, bucket)
    # Then
    assert s3_file.key == key
    assert s3_file.base_path == 'test/s3/path'
    assert s3_file.filename == 'filename.dat'
    assert s3_file.bucket_name == bucket


def test_file_read_content_success(create_bucket_mock, create_mock_file_s3):
    # Given
    mock_bucket = 'mock_bucket'
    base_key = 'mock/base/path'
    filename = 'file1.txt'

    create_bucket_mock(mock_bucket)
    create_mock_file_s3(filename, mock_bucket, base_key)

    s3_file = S3File(base_key, filename, mock_bucket)
    # When
    file_content = s3_file.read_content()
    # Then
    assert file_content == ['file1.txt']


def test_file_read_content_exception_file_not_found(create_bucket_mock):
    # Given
    mock_bucket = 'mock_bucket'
    create_bucket_mock(mock_bucket)

    s3_file = S3File('mock/base/path', 'file.txt', mock_bucket)
    # When
    file_content = s3_file.read_content()
    # Then
    assert file_content == None


def test_file_read_content_exception(s3_client_mock):
    # Given
    s3_file = S3File('mock/base/path', 'file.fil', 'mock_bucket')
    # When
    with pytest.raises(ClientError):
        s3_file.read_content()


def test_file_save_content(create_bucket_mock):
    # Given
    mock_bucket = 'mock_bucket'
    create_bucket_mock(mock_bucket)

    s3_file = S3File('mock/base/path', 'file.fil', mock_bucket)
    # When
    s3_file.save_content('mock_content')
    # Then
    saved_content = s3_file.read_content()
    assert saved_content == ['mock_content']
