from datetime import date, datetime
from functools import lru_cache
from typing import List, Union

from chuva_vazao_utils.aws.s3.environment import Env
from chuva_vazao_utils.aws.s3.pattern_formatter.pattern_formatter import S3PatternFormatter
from chuva_vazao_utils.aws.s3.s3_models import S3File, S3Folder
from chuva_vazao_utils.entities.rain.psat_model import PsatModel, PsatDataApi


class PsatPatternFormatter(S3PatternFormatter):
    @classmethod
    def format_pattern(
        cls,
        pattern: str,
        data_date: Union[date, datetime],
    ) -> str:
        formatting_map = {
            'data_date_%Y%m%d': data_date.strftime('%Y%m%d'),
            'data_date_%Y/%m': data_date.strftime('%Y/%m'),
        }
        return pattern.format_map(formatting_map)

    @classmethod
    def get_data_date_from_filename(cls, model: PsatModel, filename: str) -> date:
        searched_patterns = ['data_date_%Y%m%d']
        return cls._get_date_from_formated_str_pattern(filename, model.filename_pattern, searched_patterns)

    @classmethod
    def get_model_base_folder(cls, model: PsatModel) -> str:
        return model.key_pattern.split('{')[0]


class PsatDataS3Api(PsatDataApi):
    formatter = PsatPatternFormatter

    @classmethod
    def _bucket(cls) -> str:
        return Env.bucket_precipitation

    @classmethod
    def get_base_folder(cls, model: PsatModel) -> S3Folder:
        return S3Folder(cls.formatter.get_model_base_folder(model), cls._bucket())

    @classmethod
    def get_data_folder(
        cls,
        model: PsatModel,
        data_date: Union[date, datetime],
    ) -> S3Folder:
        folder_path = cls.formatter.format_pattern(
            pattern=model.key_pattern,
            data_date=data_date,
        )
        return S3Folder(folder_path, cls._bucket())

    @classmethod
    def get_data_file(
        cls,
        model: PsatModel,
        data_date: Union[date, datetime],
    ) -> S3File:
        folder_path = cls.formatter.format_pattern(
            pattern=model.key_pattern,
            data_date=data_date,
        )
        filename = cls.formatter.format_pattern(
            pattern=model.filename_pattern,
            data_date=data_date,
        )
        return S3File(folder_path, filename, cls._bucket())

    @classmethod
    @lru_cache(maxsize=16)
    def list_all_data_dates(cls, model: PsatModel) -> List[date]:
        base_folder = cls.get_base_folder(model)
        all_model_keys = base_folder.list_keys()
        all_dates = [cls.formatter.get_data_date_from_filename(model, key.rsplit('/', 1)[-1]) for key in all_model_keys]
        return [d for d in all_dates if d is not None]
